{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_english(text):\n",
    "    def fn(m):\n",
    "        word = m.group()\n",
    "        if word in english_dictionary:\n",
    "            return english_dictionary.get(word)\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    text = re.sub(\"([A-Za-z]+)\", fn, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'english_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnormalize_english\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabc123A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mnormalize_english\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m word\n\u001b[0;32m----> 9\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m([A-Za-z]+)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[0;32m/usr/lib/python3.8/re.py:210\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mnormalize_english.<locals>.fn\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(m):\n\u001b[1;32m      3\u001b[0m     word \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43menglish_dictionary\u001b[49m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m english_dictionary\u001b[38;5;241m.\u001b[39mget(word)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'english_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "normalize_english(\"abc123A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_upper(text):\n",
    "    text = text.group(0)\n",
    "\n",
    "    if all([char.isupper() for char in text]):\n",
    "        return \"\".join(upper_to_kor[char] for char in text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnormalize_upper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mnormalize_upper\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_upper\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m([char\u001b[38;5;241m.\u001b[39misupper() \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text]):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(upper_to_kor[char] \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "normalize_upper(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(\"([A-Za-z]+)\",\"(ABc23일)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클리너에서 텍스트를 처리\n",
    "클리너에서의  코리안 클리너를 사용\n",
    "코리안 클리너에서는 from tensorflow_tts.utils.korean import tokenize as ko_tokenize를 활용\n",
    "https://github.com/TensorSpeech/TensorFlowTTS/blob/136877136355c82d7ba474ceb7a8f133bd84767e/tensorflow_tts/utils/korean.py#L349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_tts.inference import AutoProcessor\n",
    "from tensorflow_tts.inference import TFAutoModel\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"tensorspeech/tts-tacotron2-kss-ko\")\n",
    "input_ids = processor.text_to_sequence(text)\n",
    "tacotron2 = TFAutoModel.from_pretrained(\"tensorspeech/tts-tacotron2-kss-ko\")\n",
    "mb_melgan = TFAutoModel.from_pretrained(\"tensorspeech/tts-mb_melgan-kss-ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"마징가Z 3화\"\n",
    "\n",
    "input_ids = processor.text_to_sequence(text)\n",
    "\n",
    "# tacotron2 inference (text-to-mel)\n",
    "decoder_output, mel_outputs, stop_token_prediction, alignment_history = tacotron2.inference(\n",
    "    input_ids=tf.expand_dims(tf.convert_to_tensor(input_ids, dtype=tf.int32), 0),\n",
    "    input_lengths=tf.convert_to_tensor([len(input_ids)], tf.int32),\n",
    "    speaker_ids=tf.convert_to_tensor([0], dtype=tf.int32),\n",
    ")\n",
    "\n",
    "# melgan inference (mel-to-wav)\n",
    "audio = mb_melgan.inference(mel_outputs)[0, :, 0]\n",
    "\n",
    "# save to file\n",
    "sf.write('./audio.wav', audio, 22050, \"PCM_16\")\n",
    "\n",
    "import IPython.display as ipd\n",
    "ipd.Audio('audio.wav') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마징가제트 십삼화 더블에스오공일 시즌파이브 one two 백이십삼 이천오 백이십삼원 백이십삼호 열두시\n"
     ]
    }
   ],
   "source": [
    "text = \"마징가Z 13화 SS501 시즌5 one two 123 2005 123원 123호 12시\"\n",
    "from TN import tokenize\n",
    "from unicode import join_jamos\n",
    "merge_jamo = join_jamos(tokenize(text))\n",
    "print(merge_jamo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_korean(num_str, is_count=False):\n",
    "    if is_count:\n",
    "        num_str, unit_str = num_str.group(1), num_str.group(2)\n",
    "    else:\n",
    "        num_str, unit_str = num_str.group(), \"\"\n",
    "\n",
    "    num_str = num_str.replace(\",\", \"\")\n",
    "    num = ast.literal_eval(num_str)\n",
    "\n",
    "    if num == 0:\n",
    "        return \"영\"\n",
    "\n",
    "    check_float = num_str.split(\".\")\n",
    "    if len(check_float) == 2:\n",
    "        digit_str, float_str = check_float\n",
    "    elif len(check_float) >= 3:\n",
    "        raise Exception(\" [!] Wrong number format\")\n",
    "    else:\n",
    "        digit_str, float_str = check_float[0], None\n",
    "\n",
    "    if is_count and float_str is not None:\n",
    "        raise Exception(\" [!] `is_count` and float number does not fit each other\")\n",
    "\n",
    "    digit = int(digit_str)\n",
    "\n",
    "    if digit_str.startswith(\"-\"):\n",
    "        digit, digit_str = abs(digit), str(abs(digit))\n",
    "\n",
    "    kor = \"\"\n",
    "    size = len(str(digit))\n",
    "    tmp = []\n",
    "\n",
    "    for i, v in enumerate(digit_str, start=1):\n",
    "        v = int(v)\n",
    "\n",
    "        if v != 0:\n",
    "            if is_count:\n",
    "                tmp += count_to_kor1[v]\n",
    "            else:\n",
    "                tmp += num_to_kor1[v]\n",
    "\n",
    "            tmp += num_to_kor3[(size - i) % 4]\n",
    "\n",
    "        if (size - i) % 4 == 0 and len(tmp) != 0:\n",
    "            kor += \"\".join(tmp)\n",
    "            tmp = []\n",
    "            kor += num_to_kor2[int((size - i) / 4)]\n",
    "\n",
    "    if is_count:\n",
    "        if kor.startswith(\"한\") and len(kor) > 1:\n",
    "            kor = kor[1:]\n",
    "\n",
    "        if any(word in kor for word in count_tenth_dict):\n",
    "            kor = re.sub(\n",
    "                \"|\".join(count_tenth_dict.keys()),\n",
    "                lambda x: count_tenth_dict[x.group()],\n",
    "                kor,\n",
    "            )\n",
    "\n",
    "    if not is_count and kor.startswith(\"일\") and len(kor) > 1:\n",
    "        kor = kor[1:]\n",
    "\n",
    "    if float_str is not None:\n",
    "        kor += \"쩜 \"\n",
    "        kor += re.sub(\"\\d\", lambda x: num_to_kor[x.group()], float_str)\n",
    "\n",
    "    if num_str.startswith(\"+\"):\n",
    "        kor = \"플러스 \" + kor\n",
    "    elif num_str.startswith(\"-\"):\n",
    "        kor = \"마이너스 \" + kor\n",
    "\n",
    "    return kor + unit_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnumber_to_korean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m+3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mnumber_to_korean\u001b[0;34m(num_str, is_count)\u001b[0m\n\u001b[1;32m      3\u001b[0m     num_str, unit_str \u001b[38;5;241m=\u001b[39m num_str\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m), num_str\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     num_str, unit_str \u001b[38;5;241m=\u001b[39m \u001b[43mnum_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m num_str \u001b[38;5;241m=\u001b[39m num_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m num \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(num_str)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "number_to_korean(\"+3\", is_count=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼화 시즌쓰리 일박이일 십이번 째 사제 이번째 남편 열두시 십이등\n"
     ]
    }
   ],
   "source": [
    "text = \"3화 시즌3 1박2일 12번 째 사제 2번째 남편 12시 12등\"\n",
    "from TN import tokenize\n",
    "from unicode import join_jamos\n",
    "merge_jamo = join_jamos(tokenize(text))\n",
    "print(merge_jamo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
